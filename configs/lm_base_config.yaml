
general:
    seed: 42
    checkpoint_path: ./classic_lm_checkpoints/

trainer_params:
    max_epochs: 10
    val_check_interval: 0.25
    default_save_path: ./logs/
    gpus: 1


dataloaders:
    train_batch_size: 30
    test_batch_size: 20
    pad_len: 300
    tokenizer_type: word

model:
    vocab_size: 20226
    embeddig_dim: 256 
    hidden_size: 256

optimizer:
    learning_rate: 0.001
