
general:
    seed: 42
    checkpoint_path: ./attention_lm_checkpoints

trainer_params:
    max_epochs: 5
    val_check_interval: 0.25
    default_save_path: ./logs
    gpus: 1


dataloaders:
    train_batch_size: 30
    test_batch_size: 20
    pad_len: 300

model:
    vocab_size: 20226
    embeddig_dim: 128
    hidden_size: 128
    n_heads: 5

optimizer:
    learning_rate: 0.001
